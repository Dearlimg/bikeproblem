# 附录：详细实现代码

## 1. 数据加载模块 (data_loader.py)

```python
"""
数据加载模块
负责从CSV文件加载共享单车数据并进行基本的数据检查
"""

import pandas as pd
import os
from typing import Tuple, Optional


class DataLoader:
    """数据加载器类"""
    
    def __init__(self, data_dir: str = "data"):
        """
        初始化数据加载器
        
        Args:
            data_dir: 数据文件所在目录
        """
        self.data_dir = data_dir
    
    def load_day_data(self) -> pd.DataFrame:
        """
        加载按天聚合的数据
        
        Returns:
            包含每日数据的DataFrame
            
        Raises:
            FileNotFoundError: 如果数据文件不存在
        """
        file_path = os.path.join(self.data_dir, "day.csv")
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"数据文件不存在: {file_path}")
        
        df = pd.read_csv(file_path)
        print(f"成功加载每日数据: {len(df)} 条记录")
        return df
    
    def load_hour_data(self) -> pd.DataFrame:
        """
        加载按小时聚合的数据
        
        Returns:
            包含每小时数据的DataFrame
            
        Raises:
            FileNotFoundError: 如果数据文件不存在
        """
        file_path = os.path.join(self.data_dir, "hour.csv")
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"数据文件不存在: {file_path}")
        
        df = pd.read_csv(file_path)
        print(f"成功加载每小时数据: {len(df)} 条记录")
        return df
    
    def get_data_info(self, df: pd.DataFrame) -> None:
        """
        打印数据基本信息
        
        Args:
            df: 要检查的DataFrame
        """
        print("\n" + "="*50)
        print("数据基本信息")
        print("="*50)
        print(f"数据形状: {df.shape}")
        print(f"\n列名: {list(df.columns)}")
        print(f"\n前5行数据:")
        print(df.head())
        print(f"\n数据类型:")
        print(df.dtypes)
        print(f"\n缺失值统计:")
        print(df.isnull().sum())
        print(f"\n数据统计摘要:")
        print(df.describe())
        print("="*50 + "\n")
```

## 2. 数据预处理模块 (data_preprocessor.py)

```python
"""
数据预处理模块
负责特征工程和数据清洗
"""

import pandas as pd
import numpy as np
from typing import Tuple, Optional
from sklearn.preprocessing import StandardScaler


class DataPreprocessor:
    """数据预处理器类"""
    
    def __init__(self):
        """初始化预处理器"""
        self.scaler = StandardScaler()
        self.feature_columns = None
    
    def prepare_features(self, df: pd.DataFrame, target: str = "cnt") -> Tuple[pd.DataFrame, pd.Series]:
        """
        准备特征和目标变量
        
        Args:
            df: 原始数据DataFrame
            target: 目标变量列名
            
        Returns:
            (特征DataFrame, 目标变量Series)
        """
        # 复制数据避免修改原始数据
        data = df.copy()
        
        # 删除不需要的列
        columns_to_drop = ['instant', 'dteday', 'casual', 'registered']
        if target in columns_to_drop:
            columns_to_drop.remove(target)
        
        # 确保目标列存在
        if target not in data.columns:
            raise ValueError(f"目标列 '{target}' 不存在于数据中")
        
        # 分离特征和目标
        X = data.drop(columns=[col for col in columns_to_drop if col in data.columns])
        X = X.drop(columns=[target])
        y = data[target]
        
        # 保存特征列名
        self.feature_columns = X.columns.tolist()
        
        print(f"特征数量: {len(self.feature_columns)}")
        print(f"特征列表: {self.feature_columns}")
        print(f"目标变量统计: 均值={y.mean():.2f}, 标准差={y.std():.2f}, 最小值={y.min()}, 最大值={y.max()}")
        
        return X, y
    
    def scale_features(self, X_train: pd.DataFrame, X_test: Optional[pd.DataFrame] = None) -> Tuple[pd.DataFrame, Optional[pd.DataFrame]]:
        """
        标准化特征
        
        Args:
            X_train: 训练集特征
            X_test: 测试集特征（可选）
            
        Returns:
            (标准化后的训练集, 标准化后的测试集)
        """
        X_train_scaled = pd.DataFrame(
            self.scaler.fit_transform(X_train),
            columns=X_train.columns,
            index=X_train.index
        )
        
        if X_test is not None:
            X_test_scaled = pd.DataFrame(
                self.scaler.transform(X_test),
                columns=X_test.columns,
                index=X_test.index
            )
            return X_train_scaled, X_test_scaled
        
        return X_train_scaled, None
    
    def get_feature_importance_data(self, feature_importance: np.ndarray) -> pd.DataFrame:
        """
        获取特征重要性数据框（用于可视化）
        
        Args:
            feature_importance: 特征重要性数组
            
        Returns:
            包含特征名称和重要性的DataFrame
        """
        if self.feature_columns is None:
            raise ValueError("特征列未定义，请先调用 prepare_features")
        
        importance_df = pd.DataFrame({
            'feature': self.feature_columns,
            'importance': feature_importance
        }).sort_values('importance', ascending=False)
        
        return importance_df
```

## 3. 模型训练模块 (model_trainer.py)

```python
"""
模型训练模块
负责训练和评估回归模型
"""

import numpy as np
import pandas as pd
from typing import Dict, Tuple
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score


class ModelTrainer:
    """模型训练器类"""
    
    def __init__(self, random_state: int = 42):
        """
        初始化模型训练器
        
        Args:
            random_state: 随机种子
        """
        self.random_state = random_state
        self.models = {}
        self.best_model = None
        self.best_model_name = None
    
    def train_models(self, X: pd.DataFrame, y: pd.Series, test_size: float = 0.2) -> Dict[str, Dict]:
        """
        训练多个模型并比较性能
        
        Args:
            X: 特征数据
            y: 目标变量
            test_size: 测试集比例
            
        Returns:
            包含各模型评估指标的字典
        """
        # 划分训练集和测试集
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=self.random_state
        )
        
        print(f"\n数据划分: 训练集 {len(X_train)} 条, 测试集 {len(X_test)} 条\n")
        
        # 定义要训练的模型
        models_to_train = {
            'Linear Regression': LinearRegression(),
            'Random Forest': RandomForestRegressor(
                n_estimators=1000,
                max_depth=10,
                random_state=self.random_state,
                n_jobs=-1
            )
        }
        
        results = {}
        
        # 训练每个模型
        for name, model in models_to_train.items():
            print(f"正在训练 {name}...")
            
            # 训练模型
            model.fit(X_train, y_train)
            
            # 预测
            y_train_pred = model.predict(X_train)
            y_test_pred = model.predict(X_test)
            
            # 计算评估指标
            train_metrics = self._calculate_metrics(y_train, y_train_pred, "训练集")
            test_metrics = self._calculate_metrics(y_test, y_test_pred, "测试集")
            
            results[name] = {
                'model': model,
                'train_metrics': train_metrics,
                'test_metrics': test_metrics,
                'y_test': y_test,
                'y_test_pred': y_test_pred
            }
            
            self.models[name] = model
        
        # 选择最佳模型（基于测试集R²分数）
        best_name = max(results.keys(), key=lambda k: results[k]['test_metrics']['r2_score'])
        self.best_model = results[best_name]['model']
        self.best_model_name = best_name
        
        print(f"\n最佳模型: {self.best_model_name}")
        print(f"测试集 R² 分数: {results[best_name]['test_metrics']['r2_score']:.4f}")
        
        return results
    
    def _calculate_metrics(self, y_true: np.ndarray, y_pred: np.ndarray, dataset_name: str = "") -> Dict[str, float]:
        """
        计算回归评估指标
        
        Args:
            y_true: 真实值
            y_pred: 预测值
            dataset_name: 数据集名称（用于打印）
            
        Returns:
            包含各种评估指标的字典
        """
        mse = mean_squared_error(y_true, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_true, y_pred)
        r2 = r2_score(y_true, y_pred)
        
        metrics = {
            'mse': mse,
            'rmse': rmse,
            'mae': mae,
            'r2_score': r2
        }
        
        if dataset_name:
            print(f"\n{dataset_name}评估指标:")
            print(f"  MSE (均方误差): {mse:.2f}")
            print(f"  RMSE (均方根误差): {rmse:.2f}")
            print(f"  MAE (平均绝对误差): {mae:.2f}")
            print(f"  R² 分数: {r2:.4f}")
        
        return metrics
    
    def get_feature_importance(self) -> np.ndarray:
        """
        获取最佳模型的特征重要性
        
        Returns:
            特征重要性数组
            
        Raises:
            ValueError: 如果模型不是RandomForest或未训练
        """
        if self.best_model is None:
            raise ValueError("模型尚未训练")
        
        if hasattr(self.best_model, 'feature_importances_'):
            return self.best_model.feature_importances_
        elif hasattr(self.best_model, 'coef_'):
            # 对于线性回归，使用系数的绝对值作为重要性
            return np.abs(self.best_model.coef_)
        else:
            raise ValueError("模型不支持特征重要性提取")
    
    def predict(self, X: pd.DataFrame) -> np.ndarray:
        """
        使用最佳模型进行预测
        
        Args:
            X: 特征数据
            
        Returns:
            预测值数组
        """
        if self.best_model is None:
            raise ValueError("模型尚未训练")
        
        return self.best_model.predict(X)
```

## 4. 主程序 (main.py)

```python
#!/usr/bin/env python3
"""
共享单车租赁预测主程序
使用机器学习模型预测共享单车租赁数量
"""

import sys
import os

# 添加src目录到路径
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from src.data_loader import DataLoader
from src.data_preprocessor import DataPreprocessor
from src.model_trainer import ModelTrainer
from src.visualizer import Visualizer


def main():
    """主函数"""
    print("="*60)
    print("共享单车租赁预测系统")
    print("="*60)
    
    # 1. 加载数据
    print("\n[步骤 1] 加载数据...")
    data_loader = DataLoader(data_dir="data")
    
    # 选择使用每日数据或每小时数据
    use_hourly = True  # 设置为True使用每小时数据，False使用每日数据
    
    if use_hourly:
        df = data_loader.load_hour_data()
    else:
        df = data_loader.load_day_data()
    
    # 显示数据信息
    data_loader.get_data_info(df)
    
    # 2. 数据预处理
    print("\n[步骤 2] 数据预处理...")
    preprocessor = DataPreprocessor()
    X, y = preprocessor.prepare_features(df, target="cnt")
    
    # 特征标准化
    X_scaled, _ = preprocessor.scale_features(X)
    
    # 3. 模型训练
    print("\n[步骤 3] 模型训练...")
    trainer = ModelTrainer(random_state=42)
    results = trainer.train_models(X_scaled, y, test_size=0.2)
    
    # 4. 可视化结果
    print("\n[步骤 4] 生成可视化结果...")
    visualizer = Visualizer(output_dir="output")
    
    # 绘制每个模型的预测结果
    for model_name, result in results.items():
        visualizer.plot_predictions(
            result['y_test'],
            result['y_test_pred'],
            model_name
        )
        visualizer.plot_residuals(
            result['y_test'],
            result['y_test_pred'],
            model_name
        )
    
    # 绘制模型对比
    visualizer.plot_model_comparison(results)
    
    # 绘制特征重要性
    if trainer.best_model is not None:
        feature_importance = trainer.get_feature_importance()
        importance_df = preprocessor.get_feature_importance_data(feature_importance)
        visualizer.plot_feature_importance(importance_df, top_n=10)
    
    # 5. 总结
    print("\n" + "="*60)
    print("训练完成！")
    print("="*60)
    print(f"\n最佳模型: {trainer.best_model_name}")
    best_result = results[trainer.best_model_name]
    print(f"测试集 R² 分数: {best_result['test_metrics']['r2_score']:.4f}")
    print(f"测试集 RMSE: {best_result['test_metrics']['rmse']:.2f}")
    print(f"测试集 MAE: {best_result['test_metrics']['mae']:.2f}")
    print(f"\n所有可视化结果已保存至 output/ 目录")
    print("="*60)


if __name__ == "__main__":
    main()
```

## 5. 运行说明

### 5.1 环境配置

```bash
# 安装依赖
pip install -r requirements.txt
```

### 5.2 运行程序

```bash
# 运行主程序
python main.py

# 运行结果分析
python analyze_results.py
```

### 5.3 输出结果

程序运行后会生成：
- 模型性能指标（控制台输出）
- 可视化图表（保存在output/目录）
- 特征重要性分析结果

