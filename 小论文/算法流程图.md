# 随机森林算法流程图

## 训练流程图

```
开始
  ↓
输入训练数据 (X_train, y_train)
  ↓
初始化：trees = []（空列表）
  ↓
┌─────────────────────────────────┐
│ FOR i = 1 TO n_estimators (1000) │
│                                   │
│   1. Bootstrap采样                │
│      - 有放回随机抽取n个样本       │
│      - 得到 X_boot, y_boot       │
│                                   │
│   2. 随机特征选择                 │
│      - 随机选择m个特征             │
│      - X_boot = X_boot[:, features]│
│                                   │
│   3. 构建决策树                   │
│      - 使用 X_boot, y_boot        │
│      - 最大深度 max_depth=10      │
│      - 递归构建树                 │
│                                   │
│   4. 保存树                       │
│      - trees.append((tree, features))│
│                                   │
└─────────────────────────────────┘
  ↓
返回随机森林模型 RF = {trees: trees}
  ↓
结束
```

## 决策树构建流程图

```
开始构建树 (X, y, depth=0)
  ↓
检查停止条件
  ├─ depth >= max_depth? → 是 → 返回叶子节点（平均值）
  ├─ 样本数 < 2? → 是 → 返回叶子节点（平均值）
  └─ 否 → 继续
  ↓
寻找最佳分割点
  ├─ 遍历所有特征
  ├─ 遍历所有可能的分割阈值
  ├─ 计算每个分割的MSE
  └─ 选择MSE最小的分割点
  ↓
根据分割点分割数据
  ├─ left_mask = X[:, feature] <= threshold
  └─ right_mask = ~left_mask
  ↓
递归构建子树
  ├─ 左子树 = build_tree(X[left_mask], y[left_mask], depth+1)
  └─ 右子树 = build_tree(X[right_mask], y[right_mask], depth+1)
  ↓
返回内部节点
  ├─ feature: 分割特征
  ├─ threshold: 分割阈值
  ├─ left: 左子树
  └─ right: 右子树
```

## 预测流程图

```
开始预测 (X_test)
  ↓
初始化 predictions = []
  ↓
┌─────────────────────────────────┐
│ FOR (tree, features) IN RF.trees│
│                                   │
│   1. 提取特征子集                 │
│      - X_subset = X_test[:, features]│
│                                   │
│   2. 树预测                       │
│      - pred = tree.predict(X_subset)│
│                                   │
│   3. 收集预测值                   │
│      - predictions.append(pred)  │
│                                   │
└─────────────────────────────────┘
  ↓
计算平均值
  - y_pred = mean(predictions)
  ↓
返回预测结果 y_pred
  ↓
结束
```

## 系统整体流程图

```
原始数据 (hour.csv)
  ↓
数据加载
  - 读取CSV文件
  - 数据检查
  ↓
数据预处理
  - 特征选择（删除无关列）
  - 特征标准化（StandardScaler）
  - 数据划分（训练集80%，测试集20%）
  ↓
模型训练
  - 随机森林训练（1000棵树）
  - 线性回归训练（对比）
  ↓
模型评估
  - 计算R²、RMSE、MAE
  - 特征重要性分析
  - 残差分析
  ↓
结果可视化
  - 预测值vs真实值图
  - 残差分析图
  - 特征重要性图
  - 模型对比图
  ↓
输出结果
  - 性能指标
  - 可视化图表
  - 分析报告
```

